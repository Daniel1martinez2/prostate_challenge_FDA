{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder, PowerTransformer\n",
    "from bayes_opt import BayesianOptimization\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder, PowerTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pq.read_table('data/df_train.parquet').to_pandas()\n",
    "df_test = pq.read_table('data/df_test.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [\n",
    "    'Cant_gr_flia', \n",
    "    'Cant_riesgos_flia_mean', \n",
    "    'cantidad_serv_flia', \n",
    "    'CANTIDAD_SERVICIOS', \n",
    "    'conteo_dx_diferentes', \n",
    "    'EDAD', \n",
    "    'psa_max_gr_flia', \n",
    "    'psa_min_gr_flia', \n",
    "    'Pendiente', \n",
    "    'Pendiente_flia', \n",
    "    'Promedio_costo', \n",
    "    'Promedio_costo_flia', \n",
    "    'psa_max_gr_flia', \n",
    "    'psa_min_gr_flia', \n",
    "    'MEDICAMENTOS', \n",
    "    'MEDICINA ESPECIALIZADA', \n",
    "    'MEDICINA GENERAL', \n",
    "    'TIEMPO_AFILIACION', \n",
    "    'TIEMPO_ULTIMA_CITA', \n",
    "    'PERDIDA_DE_PESO', \n",
    "    'Intercepto', \n",
    "    'Intercepto_flia', \n",
    "    'Cant_Fliar_CP', \n",
    "    'Cant_Fliar_riesgos'\n",
    "]\n",
    "\n",
    "categorical_columns = [\n",
    "    'AGRUPACION_DIASTOLICA', \n",
    "    'AGRUPACION_SISTOLICA', \n",
    "    'CANCER_MAMA_FAMILIAR', \n",
    "    'CANCER_OTRO_SITIO', \n",
    "    'CORONARIOS', \n",
    "    'CANCER_OTRO_SITIO_FAMILIAR',\n",
    "    'CORONARIOS_FAMILIAR', \n",
    "    'CEREBRAL', \n",
    "    'CEREBRAL_FAMILIAR', \n",
    "    'DIABETES', \n",
    "    'DIABETES_FAMILIAR', \n",
    "    'ENFERMEDAD_RENAL', \n",
    "    'ENFERMEDAD_RENAL_FAMILIAR', \n",
    "    'HIPERTENSION', \n",
    "    'HIPERTENSION_FAMILIAR', \n",
    "    'OTROS_ANTECEDENTES_VASCULARES', \n",
    "    'RIESGOS', \n",
    "    'ESTADO_CIVI', \n",
    "    'estrato', \n",
    "    'parentesco', \n",
    "    'PROGRAMA', \n",
    "]\n",
    "\n",
    "nominal_columns = [\n",
    "    'ESTADO_CIVI', 'PROGRAMA', 'parentesco', 'CANCER_MAMA_FAMILIAR', 'CANCER_OTRO_SITIO',\n",
    "    'CANCER_OTRO_SITIO_FAMILIAR', 'HIPERTENSION', 'HIPERTENSION_FAMILIAR',\n",
    "    'DIABETES', 'DIABETES_FAMILIAR', 'CORONARIOS', 'CORONARIOS_FAMILIAR',\n",
    "    'CEREBRAL', 'CEREBRAL_FAMILIAR', 'ENFERMEDAD_RENAL', 'ENFERMEDAD_RENAL_FAMILIAR',\n",
    "    'OTROS_ANTECEDENTES_VASCULARES'\n",
    "]\n",
    "\n",
    "ordinal_columns = ['estrato', 'AGRUPACION_SISTOLICA', 'AGRUPACION_DIASTOLICA', 'IMC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lets use the 40% of the entire data\n",
    "# df_train = df_train.sample(frac=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=['Target'])\n",
    "y = df_train['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessor pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal_encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "nominal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('ord', ordinal_transformer, ordinal_columns),\n",
    "        ('nom', nominal_transformer, nominal_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('xgb', XGBClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "feature_names = xgb_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "xgb_model = xgb_pipeline.named_steps['xgb']\n",
    "feature_importances = xgb_model.feature_importances_\n",
    "\n",
    "sorted_idx = np.argsort(feature_importances)[::-1]\n",
    "top_20_idx = sorted_idx[:20]\n",
    "top_20_features = feature_names[top_20_idx]\n",
    "\n",
    "def get_original_columns(features, feature_names):\n",
    "    original_columns = []\n",
    "    for feature in features:\n",
    "        original_col = feature.split('__')[1]\n",
    "        if (original_col in feature_names):\n",
    "            original_columns.append(original_col)\n",
    "    return list(set(original_columns))\n",
    "\n",
    "\n",
    "selected_numeric_columns = get_original_columns(top_20_features, numeric_columns)\n",
    "selected_ordinal_columns = get_original_columns(top_20_features, ordinal_columns)\n",
    "selected_nominal_columns = get_original_columns(top_20_features, nominal_columns)\n",
    "\n",
    "\n",
    "reduced_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, selected_numeric_columns),\n",
    "        ('ord', ordinal_transformer, selected_ordinal_columns),\n",
    "        ('nom', nominal_transformer, selected_nominal_columns)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest optimization\n",
    "- Best parameters found: {'target': 0.82463421122639, 'params': {'max_depth': 25.0, 'max_features': 0.2, 'min_samples_leaf': 1.0, 'min_samples_split': 2.0, 'n_components_pca': 6.0, 'n_estimators': 562.6480841236934}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# # Define the Random Forest evaluation function using accuracy as the metric\n",
    "# def rf_evaluate(n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features, n_components_pca):\n",
    "#     # Create a complete pipeline: Preprocessing + RandomForest\n",
    "#     model_pipeline = Pipeline([\n",
    "#         # Include the preprocessing pipeline\n",
    "#         ('preprocessor', reduced_preprocessor),\n",
    "#         ('pca', PCA(n_components=int(n_components_pca))),  # Add PCA after preprocessing\n",
    "#         ('rf', RandomForestClassifier(n_estimators=int(n_estimators),\n",
    "#                                       max_depth=int(max_depth),\n",
    "#                                       min_samples_split=int(min_samples_split),\n",
    "#                                       min_samples_leaf=int(min_samples_leaf),\n",
    "#                                       max_features=max_features,\n",
    "#                                       random_state=42))  # Random Forest with hyperparameters\n",
    "#     ])\n",
    "\n",
    "#     stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#     # accuracy_scores = cross_val_score(\n",
    "#     #     model_pipeline, X_train, y_train, cv=stratified_kfold, scoring='accuracy', n_jobs=-1)\n",
    "#     roc_auc_scores = cross_val_score(\n",
    "#         model_pipeline, X_train, y_train, cv=stratified_kfold, scoring='roc_auc', n_jobs=-1\n",
    "#     )\n",
    "\n",
    "#     return roc_auc_scores.mean()\n",
    "\n",
    "# pbounds = {\n",
    "#     'n_estimators': (400, 600),\n",
    "#     'max_depth': (25, 35),\n",
    "#     'min_samples_split': (2, 8),\n",
    "#     'min_samples_leaf': (1, 8),\n",
    "#     'max_features': (0.1, 0.2),\n",
    "#     'n_components_pca': (1, 5)\n",
    "# }\n",
    "\n",
    "# # Set up the Bayesian optimizer\n",
    "# optimizer = BayesianOptimization(\n",
    "#     f=rf_evaluate,\n",
    "#     pbounds=pbounds,\n",
    "#     random_state=42,\n",
    "#     verbose=2  # Verbose to see progress\n",
    "# )\n",
    "\n",
    "# # Run the optimization\n",
    "# # 10 random points first, then 32 iterations of optimization\n",
    "# optimizer.maximize(init_points=10, n_iter=30)\n",
    "\n",
    "# # Output the best parameters\n",
    "# best_params = optimizer.max\n",
    "# print(\"Best parameters found:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.decomposition import PCA\n",
    "# import pandas as pd\n",
    "\n",
    "# # Best parameters from Bayesian Optimization\n",
    "# best_params = {\n",
    "#     'max_depth': int(25.452039720948832),\n",
    "#     'max_features': 0.2,\n",
    "#     'min_samples_leaf': int(1.0),\n",
    "#     'min_samples_split': int(2.0),\n",
    "#     'n_components_pca': int(5.0),\n",
    "#     'n_estimators': int(552.5290750051523)\n",
    "# }\n",
    "\n",
    "# # Create the final model pipeline with the best parameters\n",
    "# model_pipeline = Pipeline([\n",
    "#     ('preprocessor', reduced_preprocessor),  # Use your preprocessor from before\n",
    "#     ('pca', PCA(n_components=best_params['n_components_pca'])),  # PCA with the best component number\n",
    "#     ('rf', RandomForestClassifier(\n",
    "#         n_estimators=best_params['n_estimators'],\n",
    "#         max_depth=best_params['max_depth'],\n",
    "#         min_samples_split=best_params['min_samples_split'],\n",
    "#         min_samples_leaf=best_params['min_samples_leaf'],\n",
    "#         max_features=best_params['max_features'],\n",
    "#         random_state=42\n",
    "#     ))\n",
    "# ])\n",
    "\n",
    "# # Fit the model on the training data\n",
    "# model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# predictions = model_pipeline.predict(df_test)\n",
    "\n",
    "# # Step 8: Create submission file\n",
    "# final_df = pd.DataFrame({\n",
    "#     'ID': df_test.index,  # Assuming df_test has the ID as index or column\n",
    "#     'Target': predictions\n",
    "# })\n",
    "\n",
    "# # Save the submission\n",
    "# submission_file = 'submission_rf.csv'\n",
    "# final_df.to_csv(submission_file, index=False)\n",
    "# print(f\"Submission file {submission_file} created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN optimization\n",
    "- so far: Best parameters found: {'target': 0.7156158552806597, 'params': {'n_components_pca': 5.0, 'n_neighbors': 50.0, 'p': 2.0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from bayes_opt import BayesianOptimization\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# # Define the KNN evaluation function using accuracy as the metric\n",
    "# def knn_evaluate(n_neighbors, p, n_components_pca):\n",
    "#     # Create a complete pipeline: Preprocessing + KNN\n",
    "#     model_pipeline = Pipeline([\n",
    "#         ('preprocessor', reduced_preprocessor),\n",
    "#         ('pca', PCA(n_components=int(n_components_pca))),\n",
    "#         ('knn', KNeighborsClassifier(n_neighbors=int(n_neighbors), p=int(p), n_jobs=-1))\n",
    "#     ])\n",
    "\n",
    "#     stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#     # Cross-validation\n",
    "#     accuracy_scores = cross_val_score(\n",
    "#         model_pipeline, X_train, y_train, cv=stratified_kfold, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "#     return accuracy_scores.mean()\n",
    "\n",
    "# # Define parameter bounds for Bayesian Optimization\n",
    "# pbounds = {\n",
    "#     'n_neighbors': (3, 50),  # KNN neighbors range\n",
    "#     'p': (1, 2),  # Distance metric (1: Manhattan, 2: Euclidean)\n",
    "#     'n_components_pca': (2, 5)  # PCA components range\n",
    "# }\n",
    "\n",
    "# # Set up the Bayesian optimizer\n",
    "# optimizer = BayesianOptimization(\n",
    "#     f=knn_evaluate,\n",
    "#     pbounds=pbounds,\n",
    "#     random_state=42,\n",
    "#     verbose=2  # Verbose to see progress\n",
    "# )\n",
    "\n",
    "# # Run the optimization\n",
    "# # 10 random points first, then 30 iterations of optimization\n",
    "# optimizer.maximize(init_points=10, n_iter=30)\n",
    "\n",
    "# # Output the best parameters\n",
    "# best_params = optimizer.max\n",
    "# print(\"Best parameters found:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from bayes_opt import BayesianOptimization\n",
    "\n",
    "# # Define the SVM evaluation function using ROC AUC as the metric\n",
    "# def svm_evaluate(C, gamma, kernel, n_components_pca):\n",
    "#     # Convert kernel index to a valid kernel string\n",
    "#     kernel_options = ['linear', 'rbf', 'poly']\n",
    "#     kernel = kernel_options[int(kernel)]\n",
    "\n",
    "#     # Create a complete pipeline: Preprocessing + PCA + SVM\n",
    "#     model_pipeline = Pipeline([\n",
    "#         ('preprocessor', reduced_preprocessor),\n",
    "#         ('pca', PCA(n_components=int(n_components_pca))),  # Add PCA after preprocessing\n",
    "#         ('svm', SVC(C=C, gamma=gamma, kernel=kernel, random_state=42, probability=True))\n",
    "#     ])\n",
    "\n",
    "#     stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#     # Use ROC AUC as the evaluation metric\n",
    "#     roc_auc_scores = cross_val_score(\n",
    "#         model_pipeline, X_train, y_train, cv=stratified_kfold, scoring='roc_auc', n_jobs=-1\n",
    "#     )\n",
    "\n",
    "#     return roc_auc_scores.mean()\n",
    "\n",
    "# # Parameter bounds for SVM optimization\n",
    "# pbounds = {\n",
    "#     'C': (0.1, 10),                # Regularization parameter\n",
    "#     'gamma': (0.0001, 1),          # Kernel coefficient\n",
    "#     'kernel': (0, 2),              # Kernel type (0: linear, 1: rbf, 2: poly)\n",
    "#     'n_components_pca': (1, 5)     # PCA components\n",
    "# }\n",
    "\n",
    "# # Set up the Bayesian optimizer\n",
    "# optimizer = BayesianOptimization(\n",
    "#     f=svm_evaluate,\n",
    "#     pbounds=pbounds,\n",
    "#     random_state=42,\n",
    "#     verbose=2  # Verbose to see progress\n",
    "# )\n",
    "\n",
    "# # Run the optimization\n",
    "# # 10 random points first, then 30 iterations of optimization\n",
    "# optimizer.maximize(init_points=10, n_iter=30)\n",
    "\n",
    "# # Output the best parameters\n",
    "# best_params = optimizer.max\n",
    "# print(\"Best parameters found:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.decomposition import PCA\n",
    "# import pandas as pd\n",
    "\n",
    "# # Best parameters from Bayesian Optimization for SVM\n",
    "# best_svm_params = {\n",
    "#     'C': 9.69511928814146,\n",
    "#     'gamma': 0.804355672916069,\n",
    "#     'kernel': round(0.9545838701817976),\n",
    "#     'n_components_pca': int(4.640990598805696)\n",
    "# }\n",
    "\n",
    "# # Map the kernel index to the actual kernel type\n",
    "# kernel_options = ['linear', 'rbf', 'poly']\n",
    "# kernel = kernel_options[best_svm_params['kernel']]\n",
    "\n",
    "# # Create the SVM model pipeline with the best parameters\n",
    "# model_pipeline = Pipeline([\n",
    "#     ('preprocessor', reduced_preprocessor),  # Use your preprocessor from before\n",
    "#     ('pca', PCA(n_components=best_svm_params['n_components_pca'])),  # PCA with the best component number\n",
    "#     ('svm', SVC(\n",
    "#         C=best_svm_params['C'],\n",
    "#         gamma=best_svm_params['gamma'],\n",
    "#         kernel=kernel,\n",
    "#         random_state=42,\n",
    "#         probability=True  # To enable probability estimates for ROC AUC\n",
    "#     ))\n",
    "# ])\n",
    "\n",
    "# # Fit the model on the training data\n",
    "# model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test set (probabilities for ROC AUC)\n",
    "# predictions_proba = model_pipeline.predict_proba(df_test)[:, 1]  # Get the probability for the positive class\n",
    "\n",
    "# # Prepare the submission dataframe (replace 'Id' with the actual ID column from your test set)\n",
    "# # Step 8: Create submission file\n",
    "# final_df = pd.DataFrame({\n",
    "#     'ID': df_test.index,  # Assuming df_test has the ID as index or column\n",
    "#     'Target': predictions_proba\n",
    "# })\n",
    "\n",
    "# # Save the submission\n",
    "# submission_file = 'submission.csv'\n",
    "# final_df.to_csv(submission_file, index=False)\n",
    "# print(f\"Submission file {submission_file} created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG-Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.impute import SimpleImputer, KNNImputer\n",
    "# from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.decomposition import PCA\n",
    "# from bayes_opt import BayesianOptimization\n",
    "\n",
    "# # Define the ultimate evaluation function for XGBoost using ROC AUC\n",
    "# def xgb_evaluate(n_estimators, max_depth, learning_rate, subsample, colsample_bytree, gamma, min_child_weight, reg_alpha, reg_lambda,\n",
    "#                  imputer_type, n_neighbors_knn, n_components_pca, k_folds):\n",
    "    \n",
    "#     # Preprocessing: Set imputation for numeric columns\n",
    "#     if imputer_type < 0.5:  # SimpleImputer mean\n",
    "#         numeric_imputer = SimpleImputer(strategy='mean')\n",
    "#     else:  # KNN Imputer\n",
    "#         numeric_imputer = KNNImputer(n_neighbors=int(n_neighbors_knn))\n",
    "    \n",
    "#     # Define the preprocessing pipeline for each type of data\n",
    "#     numeric_transformer = Pipeline(steps=[\n",
    "#         ('imputer', numeric_imputer),\n",
    "#         ('scaler', StandardScaler())\n",
    "#     ])\n",
    "\n",
    "#     ordinal_transformer = Pipeline(steps=[\n",
    "#         ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#         ('ordinal_encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "#     ])\n",
    "\n",
    "#     nominal_transformer = Pipeline(steps=[\n",
    "#         ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#         ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "#     ])\n",
    "\n",
    "#     # Define the complete ColumnTransformer\n",
    "#     preprocessor = ColumnTransformer(\n",
    "#         transformers=[\n",
    "#             ('num', numeric_transformer, numeric_columns),\n",
    "#             ('ord', ordinal_transformer, ordinal_columns),\n",
    "#             ('nom', nominal_transformer, nominal_columns)\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     # Create the model pipeline with PCA and XGBoost\n",
    "#     model_pipeline = Pipeline([\n",
    "#         ('preprocessor', preprocessor),\n",
    "#         ('pca', PCA(n_components=int(n_components_pca))),\n",
    "#         ('xgb', XGBClassifier(\n",
    "#             n_estimators=int(n_estimators),\n",
    "#             max_depth=int(max_depth),\n",
    "#             learning_rate=learning_rate,\n",
    "#             subsample=subsample,\n",
    "#             colsample_bytree=colsample_bytree,\n",
    "#             gamma=gamma,\n",
    "#             min_child_weight=min_child_weight,\n",
    "#             reg_alpha=reg_alpha,\n",
    "#             reg_lambda=reg_lambda,\n",
    "#             random_state=42,\n",
    "#             eval_metric='logloss'\n",
    "#         ))\n",
    "#     ])\n",
    "\n",
    "#     # Stratified K-Fold Cross Validation\n",
    "#     stratified_kfold = StratifiedKFold(n_splits=int(k_folds), shuffle=True, random_state=42)\n",
    "\n",
    "#     # Evaluate using ROC AUC\n",
    "#     roc_auc_scores = cross_val_score(\n",
    "#         model_pipeline, X_train, y_train, cv=stratified_kfold, scoring='roc_auc', n_jobs=-1\n",
    "#     )\n",
    "\n",
    "#     return roc_auc_scores.mean()\n",
    "\n",
    "# # Parameter bounds for Bayesian Optimization\n",
    "# pbounds = {\n",
    "#     'n_estimators': (50, 1000),          # Number of trees\n",
    "#     'max_depth': (3, 12),                # Maximum depth of the tree\n",
    "#     'learning_rate': (0.01, 0.3),        # Learning rate\n",
    "#     'subsample': (0.5, 1.0),             # Subsample ratio\n",
    "#     'colsample_bytree': (0.5, 1.0),      # Subsample ratio of columns\n",
    "#     'gamma': (0, 5),                     # Minimum loss reduction\n",
    "#     'min_child_weight': (1, 10),         # Minimum child weight\n",
    "#     'reg_alpha': (0, 5),                 # L1 regularization\n",
    "#     'reg_lambda': (0, 5),                # L2 regularization\n",
    "    \n",
    "#     # Preprocessing related parameters\n",
    "#     'imputer_type': (0, 1),              # 0: Mean imputer, 1: KNN Imputer\n",
    "#     'n_neighbors_knn': (3, 10),          # Number of neighbors for KNN Imputer\n",
    "#     'n_components_pca': (1, 20),         # PCA components\n",
    "\n",
    "#     # K-Fold cross validation parameter\n",
    "#     'k_folds': (3, 10)                   # Number of K-Folds\n",
    "# }\n",
    "\n",
    "# # Set up the Bayesian optimizer\n",
    "# optimizer = BayesianOptimization(\n",
    "#     f=xgb_evaluate,\n",
    "#     pbounds=pbounds,\n",
    "#     random_state=42,\n",
    "#     verbose=2  # Verbose to see progress\n",
    "# )\n",
    "\n",
    "# # Run the optimization\n",
    "# optimizer.maximize(init_points=2, n_iter=3)\n",
    "\n",
    "# # Output the best parameters\n",
    "# best_params = optimizer.max\n",
    "# print(\"Best parameters found:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = {'target': 0.798312289413439,\n",
    "#  'params': {'colsample_bytree': 1.0,\n",
    "#   'gamma': 0.0,\n",
    "#   'imputer_type': 1.0,\n",
    "#   'k_folds': 10.0,\n",
    "#   'learning_rate': 0.01,\n",
    "#   'max_depth': 12.0,\n",
    "#   'min_child_weight': 1.0,\n",
    "#   'n_components_pca': 20.0,\n",
    "#   'n_estimators': 262.8509615896416,\n",
    "#   'n_neighbors_knn': 3.0,\n",
    "#   'reg_alpha': 0.0,\n",
    "#   'reg_lambda': 0.0,\n",
    "#   'subsample': 0.5}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # Define the best parameters found\n",
    "# best_params_xg = best_params['params']\n",
    "\n",
    "# # Define preprocessing based on the best imputer type (SimpleImputer mean in this case)\n",
    "# numeric_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='mean')),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# ordinal_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('ordinal_encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "# ])\n",
    "\n",
    "# nominal_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "# ])\n",
    "\n",
    "# # Create the final preprocessor with the best found settings\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numeric_transformer, numeric_columns),\n",
    "#         ('ord', ordinal_transformer, ordinal_columns),\n",
    "#         ('nom', nominal_transformer, nominal_columns)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Create the final model pipeline with PCA and XGBoost\n",
    "# final_model_pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('pca', PCA(n_components=int(best_params_xg['n_components_pca']))),\n",
    "#     ('xgb', XGBClassifier(\n",
    "#         n_estimators=int(best_params_xg['n_estimators']),\n",
    "#         max_depth=int(best_params_xg['max_depth']),\n",
    "#         learning_rate=best_params_xg['learning_rate'],\n",
    "#         subsample=best_params_xg['subsample'],\n",
    "#         colsample_bytree=best_params_xg['colsample_bytree'],\n",
    "#         gamma=best_params_xg['gamma'],\n",
    "#         min_child_weight=best_params_xg['min_child_weight'],\n",
    "#         reg_alpha=best_params_xg['reg_alpha'],\n",
    "#         reg_lambda=best_params_xg['reg_lambda'],\n",
    "#         random_state=42,\n",
    "#         use_label_encoder=False,\n",
    "#         eval_metric='logloss'\n",
    "#     ))\n",
    "# ])\n",
    "\n",
    "# # Fit the model on the training data\n",
    "# final_model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test data\n",
    "# y_test_predictions = final_model_pipeline.predict(df_test)\n",
    "\n",
    "# # Create the submission DataFrame\n",
    "# final_df = pd.DataFrame({\n",
    "#     'ID': df_test.index,  # Assuming df_test has the 'ID' as index\n",
    "#     'Target': y_test_predictions\n",
    "# })\n",
    "\n",
    "# # Save the submission file\n",
    "# submission_file = 'submission_xg.csv'\n",
    "# final_df.to_csv(submission_file, index=False)\n",
    "# print(f\"Submission file {submission_file} created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | min_ch... | n_comp... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(2057) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(2058) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(2059) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(2060) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(2061) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(2062) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(2063) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(2064) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(2065) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(2066) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(2067) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(2068) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.5225   \u001b[39m | \u001b[39m0.6873   \u001b[39m | \u001b[39m4.754    \u001b[39m | \u001b[39m0.2223   \u001b[39m | \u001b[39m8.388    \u001b[39m | \u001b[39m2.404    \u001b[39m | \u001b[39m1.624    \u001b[39m | \u001b[39m58.71    \u001b[39m | \u001b[39m0.9331   \u001b[39m |\n",
      "| \u001b[35m2        \u001b[39m | \u001b[35m0.5249   \u001b[39m | \u001b[35m0.8006   \u001b[39m | \u001b[35m3.54     \u001b[39m | \u001b[35m0.01597  \u001b[39m | \u001b[35m11.73    \u001b[39m | \u001b[35m8.492    \u001b[39m | \u001b[35m1.849    \u001b[39m | \u001b[35m77.27    \u001b[39m | \u001b[35m0.5917   \u001b[39m |\n",
      "| \u001b[35m3        \u001b[39m | \u001b[35m0.5325   \u001b[39m | \u001b[35m0.6521   \u001b[39m | \u001b[35m2.624    \u001b[39m | \u001b[35m0.1353   \u001b[39m | \u001b[35m5.621    \u001b[39m | \u001b[35m6.507    \u001b[39m | \u001b[35m1.558    \u001b[39m | \u001b[35m93.82    \u001b[39m | \u001b[35m0.6832   \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.5277   \u001b[39m | \u001b[39m0.728    \u001b[39m | \u001b[39m3.926    \u001b[39m | \u001b[39m0.06791  \u001b[39m | \u001b[39m7.628    \u001b[39m | \u001b[39m6.332    \u001b[39m | \u001b[39m1.186    \u001b[39m | \u001b[39m141.1    \u001b[39m | \u001b[39m0.5853   \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.5233   \u001b[39m | \u001b[39m0.5325   \u001b[39m | \u001b[39m4.744    \u001b[39m | \u001b[39m0.29     \u001b[39m | \u001b[39m10.28    \u001b[39m | \u001b[39m3.742    \u001b[39m | \u001b[39m1.391    \u001b[39m | \u001b[39m152.6    \u001b[39m | \u001b[39m0.7201   \u001b[39m |\n",
      "| \u001b[35m6        \u001b[39m | \u001b[35m0.5326   \u001b[39m | \u001b[35m0.6337   \u001b[39m | \u001b[35m2.605    \u001b[39m | \u001b[35m0.1169   \u001b[39m | \u001b[35m5.603    \u001b[39m | \u001b[35m6.488    \u001b[39m | \u001b[35m1.54     \u001b[39m | \u001b[35m93.8     \u001b[39m | \u001b[35m0.6648   \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.527    \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.01     \u001b[39m | \u001b[39m3.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m100.0    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.5234   \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.01     \u001b[39m | \u001b[39m3.0      \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m89.99    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.5259   \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m3.463    \u001b[39m | \u001b[39m0.01     \u001b[39m | \u001b[39m6.45     \u001b[39m | \u001b[39m3.541    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m94.11    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.5265   \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m1.614    \u001b[39m | \u001b[39m0.01     \u001b[39m | \u001b[39m4.623    \u001b[39m | \u001b[39m7.299    \u001b[39m | \u001b[39m1.393    \u001b[39m | \u001b[39m95.01    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.5298   \u001b[39m | \u001b[39m0.5985   \u001b[39m | \u001b[39m2.946    \u001b[39m | \u001b[39m0.04789  \u001b[39m | \u001b[39m5.937    \u001b[39m | \u001b[39m6.703    \u001b[39m | \u001b[39m1.685    \u001b[39m | \u001b[39m92.54    \u001b[39m | \u001b[39m0.6687   \u001b[39m |\n",
      "| \u001b[35m12       \u001b[39m | \u001b[35m0.5972   \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m2.062    \u001b[39m | \u001b[35m0.3      \u001b[39m | \u001b[35m5.408    \u001b[39m | \u001b[35m5.64     \u001b[39m | \u001b[35m2.293    \u001b[39m | \u001b[35m93.53    \u001b[39m | \u001b[35m0.9971   \u001b[39m |\n",
      "| \u001b[35m13       \u001b[39m | \u001b[35m0.5972   \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m1.863    \u001b[39m | \u001b[35m0.3      \u001b[39m | \u001b[35m5.333    \u001b[39m | \u001b[35m5.345    \u001b[39m | \u001b[35m2.561    \u001b[39m | \u001b[35m93.48    \u001b[39m | \u001b[35m1.0      \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.5938   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.414    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m4.652    \u001b[39m | \u001b[39m5.498    \u001b[39m | \u001b[39m2.657    \u001b[39m | \u001b[39m93.38    \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.5942   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.401    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m4.581    \u001b[39m | \u001b[39m5.485    \u001b[39m | \u001b[39m2.027    \u001b[39m | \u001b[39m92.8     \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[35m16       \u001b[39m | \u001b[35m0.6213   \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m1.301    \u001b[39m | \u001b[35m0.3      \u001b[39m | \u001b[35m4.922    \u001b[39m | \u001b[35m6.374    \u001b[39m | \u001b[35m3.341    \u001b[39m | \u001b[35m92.91    \u001b[39m | \u001b[35m1.0      \u001b[39m |\n",
      "| \u001b[35m17       \u001b[39m | \u001b[35m0.6289   \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m1.144    \u001b[39m | \u001b[35m0.3      \u001b[39m | \u001b[35m4.681    \u001b[39m | \u001b[35m6.103    \u001b[39m | \u001b[35m4.362    \u001b[39m | \u001b[35m91.75    \u001b[39m | \u001b[35m1.0      \u001b[39m |\n",
      "| \u001b[35m18       \u001b[39m | \u001b[35m0.667    \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m0.0      \u001b[39m | \u001b[35m0.3      \u001b[39m | \u001b[35m5.463    \u001b[39m | \u001b[35m6.828    \u001b[39m | \u001b[35m5.0      \u001b[39m | \u001b[35m92.53    \u001b[39m | \u001b[35m1.0      \u001b[39m |\n",
      "| \u001b[35m19       \u001b[39m | \u001b[35m0.6849   \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m0.0      \u001b[39m | \u001b[35m0.3      \u001b[39m | \u001b[35m7.062    \u001b[39m | \u001b[35m6.983    \u001b[39m | \u001b[35m5.0      \u001b[39m | \u001b[35m91.68    \u001b[39m | \u001b[35m1.0      \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m0.677    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m6.893    \u001b[39m | \u001b[39m8.998    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m92.0     \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "=========================================================================================================================\n",
      "Best parameters found for XGBoost: {'target': 0.6848905837049022, 'params': {'colsample_bytree': 1.0, 'gamma': 0.0, 'learning_rate': 0.3, 'max_depth': 7.061560184914674, 'min_child_weight': 6.983065149641265, 'n_components_pca': 5.0, 'n_estimators': 91.68408571233837, 'subsample': 1.0}}\n",
      "XGBoost optimization completed in 14.35 seconds.\n",
      "\n",
      "|   iter    |  target   | learni... | max_depth | n_comp... | n_esti... | num_le... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 3\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 3\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 3\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 3\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.6489   \u001b[39m | \u001b[39m0.1186   \u001b[39m | \u001b[39m11.56    \u001b[39m | \u001b[39m3.928    \u001b[39m | \u001b[39m139.8    \u001b[39m | \u001b[39m16.24    \u001b[39m | \u001b[39m0.578    \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.623    \u001b[39m | \u001b[39m0.02684  \u001b[39m | \u001b[39m10.8     \u001b[39m | \u001b[39m3.404    \u001b[39m | \u001b[39m156.2    \u001b[39m | \u001b[39m10.82    \u001b[39m | \u001b[39m0.985    \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965[LightGBM] [Info] Start training from score -0.919965\n",
      "\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.542    \u001b[39m | \u001b[39m0.2514   \u001b[39m | \u001b[39m4.911    \u001b[39m | \u001b[39m1.727    \u001b[39m | \u001b[39m77.51    \u001b[39m | \u001b[39m22.17    \u001b[39m | \u001b[39m0.7624   \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 3\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.6396   \u001b[39m | \u001b[39m0.1353   \u001b[39m | \u001b[39m5.621    \u001b[39m | \u001b[39m3.447    \u001b[39m | \u001b[39m70.92    \u001b[39m | \u001b[39m21.69    \u001b[39m | \u001b[39m0.6832   \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 1\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.5418   \u001b[39m | \u001b[39m0.1423   \u001b[39m | \u001b[39m10.07    \u001b[39m | \u001b[39m1.799    \u001b[39m | \u001b[39m127.1    \u001b[39m | \u001b[39m33.7     \u001b[39m | \u001b[39m0.5232   \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 4\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 4\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 4\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "| \u001b[35m6        \u001b[39m | \u001b[35m0.6754   \u001b[39m | \u001b[35m0.2615   \u001b[39m | \u001b[35m11.69    \u001b[39m | \u001b[35m4.005    \u001b[39m | \u001b[35m139.9    \u001b[39m | \u001b[35m15.69    \u001b[39m | \u001b[35m0.537    \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 4\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 4\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 4\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 4\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.6716   \u001b[39m | \u001b[39m0.1826   \u001b[39m | \u001b[39m11.96    \u001b[39m | \u001b[39m4.229    \u001b[39m | \u001b[39m140.0    \u001b[39m | \u001b[39m14.09    \u001b[39m | \u001b[39m0.5174   \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "| \u001b[35m8        \u001b[39m | \u001b[35m0.6758   \u001b[39m | \u001b[35m0.3      \u001b[39m | \u001b[35m12.0     \u001b[39m | \u001b[35m4.635    \u001b[39m | \u001b[35m137.8    \u001b[39m | \u001b[35m14.76    \u001b[39m | \u001b[35m0.5      \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 2\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Start training from score -0.919965\n",
      "\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 2\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.629    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m12.0     \u001b[39m | \u001b[39m2.028    \u001b[39m | \u001b[39m138.5    \u001b[39m | \u001b[39m14.4     \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "| \u001b[35m10       \u001b[39m | \u001b[35m0.6833   \u001b[39m | \u001b[35m0.3      \u001b[39m | \u001b[35m9.897    \u001b[39m | \u001b[35m5.0      \u001b[39m | \u001b[35m139.1    \u001b[39m | \u001b[35m14.5     \u001b[39m | \u001b[35m0.5      \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "| \u001b[35m11       \u001b[39m | \u001b[35m0.6838   \u001b[39m | \u001b[35m0.3      \u001b[39m | \u001b[35m9.935    \u001b[39m | \u001b[35m5.0      \u001b[39m | \u001b[35m142.0    \u001b[39m | \u001b[35m14.64    \u001b[39m | \u001b[35m0.5      \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.682    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m7.564    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m141.0    \u001b[39m | \u001b[39m13.01    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5[LightGBM] [Info] Start training from score -0.919965\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.6826   \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m6.779    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m141.7    \u001b[39m | \u001b[39m15.82    \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.683    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m7.297    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m144.3    \u001b[39m | \u001b[39m13.91    \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000998 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.6267   \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m7.358    \u001b[39m | \u001b[39m2.182    \u001b[39m | \u001b[39m142.7    \u001b[39m | \u001b[39m14.25    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.6775   \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m9.42     \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m143.7    \u001b[39m | \u001b[39m11.5     \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.920338[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "| \u001b[35m17       \u001b[39m | \u001b[35m0.6847   \u001b[39m | \u001b[35m0.3      \u001b[39m | \u001b[35m10.43    \u001b[39m | \u001b[35m5.0      \u001b[39m | \u001b[35m145.7    \u001b[39m | \u001b[35m14.36    \u001b[39m | \u001b[35m1.0      \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m0.6393   \u001b[39m | \u001b[39m0.04503  \u001b[39m | \u001b[39m8.436    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m147.4    \u001b[39m | \u001b[39m12.2     \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[35m19       \u001b[39m | \u001b[35m0.6867   \u001b[39m | \u001b[35m0.3      \u001b[39m | \u001b[35m8.69     \u001b[39m | \u001b[35m5.0      \u001b[39m | \u001b[35m144.7    \u001b[39m | \u001b[35m16.87    \u001b[39m | \u001b[35m1.0      \u001b[39m |\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Number of positive: 3749, number of negative: 9407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284965 -> initscore=-0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Start training from score -0.919965\n",
      "[LightGBM] [Info] Number of positive: 3748, number of negative: 9408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 13156, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284889 -> initscore=-0.920338\n",
      "[LightGBM] [Info] Start training from score -0.920338\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m0.6833   \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m5.294    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m144.8    \u001b[39m | \u001b[39m17.18    \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "=================================================================================================\n",
      "Best parameters found for LightGBM: {'target': 0.6866657218896288, 'params': {'learning_rate': 0.3, 'max_depth': 8.69004442089769, 'n_components_pca': 5.0, 'n_estimators': 144.73172287412154, 'num_leaves': 16.86664771520256, 'subsample': 1.0}}\n",
      "LightGBM optimization completed in 40.85 seconds.\n",
      "\n",
      "|   iter    |  target   | max_depth | max_fe... | min_sa... | min_sa... | n_comp... | n_esti... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.546    \u001b[39m | \u001b[39m6.371    \u001b[39m | \u001b[39m0.9754   \u001b[39m | \u001b[39m7.588    \u001b[39m | \u001b[39m6.789    \u001b[39m | \u001b[39m1.624    \u001b[39m | \u001b[39m73.4     \u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.5269   \u001b[39m | \u001b[39m3.523    \u001b[39m | \u001b[39m0.9331   \u001b[39m | \u001b[39m6.41     \u001b[39m | \u001b[39m7.665    \u001b[39m | \u001b[39m1.082    \u001b[39m | \u001b[39m195.5    \u001b[39m |\n",
      "| \u001b[35m3        \u001b[39m | \u001b[35m0.6454   \u001b[39m | \u001b[35m10.49    \u001b[39m | \u001b[35m0.6062   \u001b[39m | \u001b[35m2.636    \u001b[39m | \u001b[35m3.467    \u001b[39m | \u001b[35m2.217    \u001b[39m | \u001b[35m128.7    \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.6069   \u001b[39m | \u001b[39m6.888    \u001b[39m | \u001b[39m0.6456   \u001b[39m | \u001b[39m6.507    \u001b[39m | \u001b[39m3.116    \u001b[39m | \u001b[39m2.169    \u001b[39m | \u001b[39m105.0    \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.6399   \u001b[39m | \u001b[39m7.105    \u001b[39m | \u001b[39m0.8926   \u001b[39m | \u001b[39m2.797    \u001b[39m | \u001b[39m6.114    \u001b[39m | \u001b[39m3.37     \u001b[39m | \u001b[39m56.97    \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.6382   \u001b[39m | \u001b[39m6.361    \u001b[39m | \u001b[39m0.6277   \u001b[39m | \u001b[39m1.912    \u001b[39m | \u001b[39m6.173    \u001b[39m | \u001b[39m4.46     \u001b[39m | \u001b[39m100.3    \u001b[39m |\n",
      "| \u001b[35m7        \u001b[39m | \u001b[35m0.661    \u001b[39m | \u001b[35m8.898    \u001b[39m | \u001b[35m0.5898   \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m6.447    \u001b[39m | \u001b[35m4.006    \u001b[39m | \u001b[35m122.0    \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.6572   \u001b[39m | \u001b[39m9.331    \u001b[39m | \u001b[39m0.6539   \u001b[39m | \u001b[39m1.942    \u001b[39m | \u001b[39m6.051    \u001b[39m | \u001b[39m3.643    \u001b[39m | \u001b[39m122.5    \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.6165   \u001b[39m | \u001b[39m3.0      \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m145.0    \u001b[39m |\n",
      "| \u001b[35m10       \u001b[39m | \u001b[35m0.6898   \u001b[39m | \u001b[35m12.0     \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m10.0     \u001b[39m | \u001b[35m2.0      \u001b[39m | \u001b[35m5.0      \u001b[39m | \u001b[35m50.0     \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.5274   \u001b[39m | \u001b[39m3.0      \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m50.0     \u001b[39m |\n",
      "| \u001b[35m12       \u001b[39m | \u001b[35m0.7181   \u001b[39m | \u001b[35m12.0     \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m2.446    \u001b[39m | \u001b[35m2.0      \u001b[39m | \u001b[35m5.0      \u001b[39m | \u001b[35m50.0     \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.6166   \u001b[39m | \u001b[39m12.0     \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m54.08    \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.7076   \u001b[39m | \u001b[39m12.0     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m4.559    \u001b[39m | \u001b[39m6.411    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m50.0     \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.6164   \u001b[39m | \u001b[39m3.0      \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m126.7    \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.6485   \u001b[39m | \u001b[39m7.053    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m3.759    \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m50.0     \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m0.6962   \u001b[39m | \u001b[39m12.0     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m8.917    \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m56.62    \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m0.5779   \u001b[39m | \u001b[39m12.0     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m164.5    \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m0.6045   \u001b[39m | \u001b[39m12.0     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m113.9    \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m0.6901   \u001b[39m | \u001b[39m12.0     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m8.673    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m56.89    \u001b[39m |\n",
      "=================================================================================================\n",
      "Best parameters found for RandomForest: {'target': 0.7181357633616827, 'params': {'max_depth': 12.0, 'max_features': 1.0, 'min_samples_leaf': 2.4462432134151713, 'min_samples_split': 2.0, 'n_components_pca': 5.0, 'n_estimators': 50.0}}\n",
      "RandomForest optimization completed in 32.81 seconds.\n",
      "\n",
      "|   iter    |  target   | n_comp... | n_neig... |     p     |  weights  |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.5955   \u001b[39m | \u001b[39m2.498    \u001b[39m | \u001b[39m14.41    \u001b[39m | \u001b[39m1.732    \u001b[39m | \u001b[39m0.5987   \u001b[39m |\n",
      "| \u001b[35m2        \u001b[39m | \u001b[35m0.6219   \u001b[39m | \u001b[35m1.624    \u001b[39m | \u001b[35m4.872    \u001b[39m | \u001b[35m1.058    \u001b[39m | \u001b[35m0.8662   \u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.607    \u001b[39m | \u001b[39m3.404    \u001b[39m | \u001b[39m11.5     \u001b[39m | \u001b[39m1.021    \u001b[39m | \u001b[39m0.9699   \u001b[39m |\n",
      "| \u001b[35m4        \u001b[39m | \u001b[35m0.6369   \u001b[39m | \u001b[35m4.33     \u001b[39m | \u001b[35m5.548    \u001b[39m | \u001b[35m1.182    \u001b[39m | \u001b[35m0.1834   \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.6067   \u001b[39m | \u001b[39m2.217    \u001b[39m | \u001b[39m9.297    \u001b[39m | \u001b[39m1.432    \u001b[39m | \u001b[39m0.2912   \u001b[39m |\n",
      "| \u001b[35m6        \u001b[39m | \u001b[35m0.6587   \u001b[39m | \u001b[35m5.0      \u001b[39m | \u001b[35m3.0      \u001b[39m | \u001b[35m2.0      \u001b[39m | \u001b[35m0.0      \u001b[39m |\n",
      "| \u001b[35m7        \u001b[39m | \u001b[35m0.747    \u001b[39m | \u001b[35m5.0      \u001b[39m | \u001b[35m3.0      \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m1.0      \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.7442   \u001b[39m | \u001b[39m4.296    \u001b[39m | \u001b[39m3.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.747    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m3.982    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.6398   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m3.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.7447   \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m3.909    \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.7429   \u001b[39m | \u001b[39m3.781    \u001b[39m | \u001b[39m3.678    \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.6184   \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m15.0     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.741    \u001b[39m | \u001b[39m4.326    \u001b[39m | \u001b[39m3.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.7442   \u001b[39m | \u001b[39m4.5      \u001b[39m | \u001b[39m3.636    \u001b[39m | \u001b[39m1.452    \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.7376   \u001b[39m | \u001b[39m2.945    \u001b[39m | \u001b[39m3.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[35m17       \u001b[39m | \u001b[35m0.754    \u001b[39m | \u001b[35m5.0      \u001b[39m | \u001b[35m4.982    \u001b[39m | \u001b[35m2.0      \u001b[39m | \u001b[35m1.0      \u001b[39m |\n",
      "| \u001b[35m18       \u001b[39m | \u001b[35m0.7613   \u001b[39m | \u001b[35m5.0      \u001b[39m | \u001b[35m7.619    \u001b[39m | \u001b[35m2.0      \u001b[39m | \u001b[35m1.0      \u001b[39m |\n",
      "| \u001b[35m19       \u001b[39m | \u001b[35m0.7633   \u001b[39m | \u001b[35m5.0      \u001b[39m | \u001b[35m9.188    \u001b[39m | \u001b[35m2.0      \u001b[39m | \u001b[35m1.0      \u001b[39m |\n",
      "| \u001b[35m20       \u001b[39m | \u001b[35m0.7641   \u001b[39m | \u001b[35m5.0      \u001b[39m | \u001b[35m8.607    \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m1.0      \u001b[39m |\n",
      "=========================================================================\n",
      "Best parameters found for K-Nearest Neighbors: {'target': 0.7641108097287652, 'params': {'n_components_pca': 5.0, 'n_neighbors': 8.607121060846424, 'p': 1.0, 'weights': 1.0}}\n",
      "K-Nearest Neighbors optimization completed in 7.64 seconds.\n",
      "\n",
      "|   iter    |  target   |     C     |   gamma   |  kernel   | n_comp... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.5602   \u001b[39m | \u001b[39m3.808    \u001b[39m | \u001b[39m0.9508   \u001b[39m | \u001b[39m1.464    \u001b[39m | \u001b[39m3.395    \u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.4439   \u001b[39m | \u001b[39m1.645    \u001b[39m | \u001b[39m0.1568   \u001b[39m | \u001b[39m0.1162   \u001b[39m | \u001b[39m4.465    \u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.539    \u001b[39m | \u001b[39m6.051    \u001b[39m | \u001b[39m0.7084   \u001b[39m | \u001b[39m0.04117  \u001b[39m | \u001b[39m4.88     \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.4933   \u001b[39m | \u001b[39m8.341    \u001b[39m | \u001b[39m0.2131   \u001b[39m | \u001b[39m0.3636   \u001b[39m | \u001b[39m1.734    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(4416) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(4417) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.5444   \u001b[39m | \u001b[39m3.112    \u001b[39m | \u001b[39m0.5252   \u001b[39m | \u001b[39m0.8639   \u001b[39m | \u001b[39m2.165    \u001b[39m |\n",
      "| \u001b[35m6        \u001b[39m | \u001b[35m0.5863   \u001b[39m | \u001b[35m4.765    \u001b[39m | \u001b[35m0.7734   \u001b[39m | \u001b[35m0.7256   \u001b[39m | \u001b[35m2.852    \u001b[39m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 178\u001b[0m\n\u001b[1;32m    176\u001b[0m run_optimization(randomforest_evaluate, randomforest_pbounds, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomForest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    177\u001b[0m run_optimization(knn_evaluate, knn_pbounds, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK-Nearest Neighbors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 178\u001b[0m \u001b[43mrun_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvm_evaluate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msvm_pbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSVM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[65], line 23\u001b[0m, in \u001b[0;36mrun_optimization\u001b[0;34m(model_eval_func, pbounds, model_name)\u001b[0m\n\u001b[1;32m     15\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m BayesianOptimization(\n\u001b[1;32m     16\u001b[0m     f\u001b[38;5;241m=\u001b[39mmodel_eval_func,\n\u001b[1;32m     17\u001b[0m     pbounds\u001b[38;5;241m=\u001b[39mpbounds,\n\u001b[1;32m     18\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m     19\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Verbose to see progress\u001b[39;00m\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Run the optimization with reduced random points and iterations\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m best_params \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mmax\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/personal/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py:374\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    372\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest(util)\n\u001b[1;32m    373\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 374\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_probe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;66;03m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bounds(\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space))\n",
      "File \u001b[0;32m~/anaconda3/envs/personal/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py:245\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39madd(params)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[0;32m~/anaconda3/envs/personal/lib/python3.9/site-packages/bayes_opt/target_space.py:373\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[_hashable(x\u001b[38;5;241m.\u001b[39mravel())]\n\u001b[1;32m    372\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keys, x))\n\u001b[0;32m--> 373\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister(x, target)\n",
      "Cell \u001b[0;32mIn[65], line 163\u001b[0m, in \u001b[0;36msvm_evaluate\u001b[0;34m(C, gamma, kernel, n_components_pca)\u001b[0m\n\u001b[1;32m    150\u001b[0m model_pipeline \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m    151\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, reduced_preprocessor),   \u001b[38;5;66;03m# Preprocessing\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpca\u001b[39m\u001b[38;5;124m'\u001b[39m, PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(n_components_pca))),  \u001b[38;5;66;03m# Add PCA\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m     ))\n\u001b[1;32m    160\u001b[0m ])\n\u001b[1;32m    162\u001b[0m stratified_kfold \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m--> 163\u001b[0m auc_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_pipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratified_kfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroc_auc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m auc_scores\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/anaconda3/envs/personal/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/personal/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/personal/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/personal/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:423\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/personal/lib/python3.9/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/personal/lib/python3.9/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/personal/lib/python3.9/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/personal/lib/python3.9/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['MallocStackLogging'] = '0'\n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# General function to run optimization for any model\n",
    "def run_optimization(model_eval_func, pbounds, model_name):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Set up the Bayesian optimizer\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=model_eval_func,\n",
    "        pbounds=pbounds,\n",
    "        random_state=42,\n",
    "        verbose=2  # Verbose to see progress\n",
    "    )\n",
    "\n",
    "    # Run the optimization with reduced random points and iterations\n",
    "    optimizer.maximize(init_points=5, n_iter=15)\n",
    "\n",
    "    best_params = optimizer.max\n",
    "    print(f\"Best parameters found for {model_name}: {best_params}\")\n",
    "    \n",
    "    print(f\"{model_name} optimization completed in {time.time() - start_time:.2f} seconds.\\n\")\n",
    "\n",
    "# 1. XGBoost Optimization\n",
    "def xgboost_evaluate(n_estimators, max_depth, learning_rate, subsample, colsample_bytree, gamma, min_child_weight, n_components_pca):\n",
    "    from xgboost import XGBClassifier\n",
    "    model_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', reduced_preprocessor),   # Use the preprocessor you defined\n",
    "        ('pca', PCA(n_components=int(n_components_pca))),  # Add PCA after preprocessing\n",
    "        ('xgb', XGBClassifier(\n",
    "            n_estimators=int(n_estimators),\n",
    "            max_depth=int(max_depth),\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            colsample_bytree=colsample_bytree,\n",
    "            gamma=gamma,\n",
    "            min_child_weight=min_child_weight,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(model_pipeline, X_train, y_train, cv=stratified_kfold, scoring='roc_auc', n_jobs=-1)\n",
    "    return auc_scores.mean()\n",
    "\n",
    "xgboost_pbounds = {\n",
    "    'n_estimators': (50, 200),\n",
    "    'max_depth': (3, 12),\n",
    "    'learning_rate': (0.01, 0.3),\n",
    "    'subsample': (0.5, 1),\n",
    "    'colsample_bytree': (0.5, 1),\n",
    "    'gamma': (0, 5),\n",
    "    'min_child_weight': (1, 10),\n",
    "    'n_components_pca': (1, 5)  # PCA added\n",
    "}\n",
    "\n",
    "# 2. LightGBM Optimization\n",
    "def lightgbm_evaluate(num_leaves, max_depth, learning_rate, n_estimators, subsample, n_components_pca):\n",
    "    from lightgbm import LGBMClassifier\n",
    "    model_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', reduced_preprocessor),   # Preprocessing\n",
    "        ('pca', PCA(n_components=int(n_components_pca))),  # Add PCA\n",
    "        ('lgbm', LGBMClassifier(\n",
    "            num_leaves=int(num_leaves),\n",
    "            max_depth=int(max_depth),\n",
    "            learning_rate=learning_rate,\n",
    "            n_estimators=int(n_estimators),\n",
    "            subsample=subsample,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(model_pipeline, X_train, y_train, cv=stratified_kfold, scoring='roc_auc', n_jobs=-1)\n",
    "    return auc_scores.mean()\n",
    "\n",
    "lightgbm_pbounds = {\n",
    "    'num_leaves': (10, 50),\n",
    "    'max_depth': (3, 12),\n",
    "    'learning_rate': (0.01, 0.3),\n",
    "    'n_estimators': (50, 200),\n",
    "    'subsample': (0.5, 1),\n",
    "    'n_components_pca': (1, 5)  # PCA added\n",
    "}\n",
    "\n",
    "# 3. RandomForest Optimization\n",
    "def randomforest_evaluate(n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features, n_components_pca):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', reduced_preprocessor),   # Preprocessing\n",
    "        ('pca', PCA(n_components=int(n_components_pca))),  # Add PCA\n",
    "        ('rf', RandomForestClassifier(\n",
    "            n_estimators=int(n_estimators),\n",
    "            max_depth=int(max_depth),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "            min_samples_leaf=int(min_samples_leaf),\n",
    "            max_features=max_features,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(model_pipeline, X_train, y_train, cv=stratified_kfold, scoring='roc_auc', n_jobs=-1)\n",
    "    return auc_scores.mean()\n",
    "\n",
    "randomforest_pbounds = {\n",
    "    'n_estimators': (50, 200),\n",
    "    'max_depth': (3, 12),\n",
    "    'min_samples_split': (2, 10),\n",
    "    'min_samples_leaf': (1, 10),\n",
    "    'max_features': (0.5, 1),\n",
    "    'n_components_pca': (1, 5)  # PCA added\n",
    "}\n",
    "\n",
    "# 4. K-Nearest Neighbors Optimization\n",
    "def knn_evaluate(n_neighbors, weights, p, n_components_pca):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    weight_options = ['uniform', 'distance']\n",
    "    model_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', reduced_preprocessor),   # Preprocessing\n",
    "        ('pca', PCA(n_components=int(n_components_pca))),  # Add PCA\n",
    "        ('knn', KNeighborsClassifier(\n",
    "            n_neighbors=int(n_neighbors),\n",
    "            weights=weight_options[int(weights)],\n",
    "            p=int(p)\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(model_pipeline, X_train, y_train, cv=stratified_kfold, scoring='roc_auc', n_jobs=-1)\n",
    "    return auc_scores.mean()\n",
    "\n",
    "knn_pbounds = {\n",
    "    'n_neighbors': (3, 15),\n",
    "    'weights': (0, 1),  # 0 for 'uniform', 1 for 'distance'\n",
    "    'p': (1, 2),\n",
    "    'n_components_pca': (1, 5)  # PCA added\n",
    "}\n",
    "\n",
    "# 5. Support Vector Machine (SVM) Optimization\n",
    "def svm_evaluate(C, gamma, kernel, n_components_pca):\n",
    "    from sklearn.svm import SVC\n",
    "    kernel_options = ['linear', 'rbf', 'poly']\n",
    "    model_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', reduced_preprocessor),   # Preprocessing\n",
    "        ('pca', PCA(n_components=int(n_components_pca))),  # Add PCA\n",
    "        ('svm', SVC(\n",
    "            C=C,\n",
    "            gamma=gamma,\n",
    "            kernel=kernel_options[int(kernel)],\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(model_pipeline, X_train, y_train, cv=stratified_kfold, scoring='roc_auc', n_jobs=-1)\n",
    "    return auc_scores.mean()\n",
    "\n",
    "svm_pbounds = {\n",
    "    'C': (0.1, 10),\n",
    "    'gamma': (0.001, 1),\n",
    "    'kernel': (0, 2),  # 0: linear, 1: rbf, 2: poly\n",
    "    'n_components_pca': (1, 5)  # PCA added\n",
    "}\n",
    "\n",
    "# Running the optimization for all models\n",
    "run_optimization(xgboost_evaluate, xgboost_pbounds, \"XGBoost\")\n",
    "run_optimization(lightgbm_evaluate, lightgbm_pbounds, \"LightGBM\")\n",
    "run_optimization(randomforest_evaluate, randomforest_pbounds, \"RandomForest\")\n",
    "run_optimization(knn_evaluate, knn_pbounds, \"K-Nearest Neighbors\")\n",
    "run_optimization(svm_evaluate, svm_pbounds, \"SVM\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 8: Create submission file\n",
    "# final_df = pd.DataFrame({\n",
    "#     'ID': df_test.index,  # Assuming df_test has the ID as index or column\n",
    "#     'Target': y_test_predictions\n",
    "# })\n",
    "\n",
    "# # Save the submission\n",
    "# submission_file = 'submission.csv'\n",
    "# final_df.to_csv(submission_file, index=False)\n",
    "# print(f\"Submission file {submission_file} created successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
