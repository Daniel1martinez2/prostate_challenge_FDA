{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prostate Cancer Worshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from bayes_opt import BayesianOptimization\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoadingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pq.read_table('data/df_train.parquet').to_pandas()\n",
    "df_test = pq.read_table('data/df_test.parquet').to_pandas()\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [\n",
    "    'Cant_gr_flia', \n",
    "    'Cant_riesgos_flia_mean', \n",
    "    'cantidad_serv_flia', \n",
    "    'CANTIDAD_SERVICIOS', \n",
    "    'conteo_dx_diferentes', \n",
    "    'EDAD', \n",
    "    'psa_max_gr_flia', \n",
    "    'psa_min_gr_flia', \n",
    "    'Pendiente', \n",
    "    'Pendiente_flia', \n",
    "    'Promedio_costo', \n",
    "    'Promedio_costo_flia', \n",
    "    'psa_max_gr_flia', \n",
    "    'psa_min_gr_flia', \n",
    "    'MEDICAMENTOS', \n",
    "    'MEDICINA ESPECIALIZADA', \n",
    "    'MEDICINA GENERAL', \n",
    "    'TIEMPO_AFILIACION', \n",
    "    'TIEMPO_ULTIMA_CITA', \n",
    "    'PERDIDA_DE_PESO', \n",
    "    'Intercepto', \n",
    "    'Intercepto_flia', \n",
    "    'Target',\n",
    "    'Cant_Fliar_CP', \n",
    "    'Cant_Fliar_riesgos'\n",
    "]\n",
    "\n",
    "categorical_columns = [\n",
    "    'AGRUPACION_DIASTOLICA', \n",
    "    'AGRUPACION_SISTOLICA', \n",
    "    'CANCER_MAMA_FAMILIAR', \n",
    "    'CANCER_OTRO_SITIO', \n",
    "    'CORONARIOS', \n",
    "    'CANCER_OTRO_SITIO_FAMILIAR',\n",
    "    'CORONARIOS_FAMILIAR', \n",
    "    'CEREBRAL', \n",
    "    'CEREBRAL_FAMILIAR', \n",
    "    'DIABETES', \n",
    "    'DIABETES_FAMILIAR', \n",
    "    'ENFERMEDAD_RENAL', \n",
    "    'ENFERMEDAD_RENAL_FAMILIAR', \n",
    "    'HIPERTENSION', \n",
    "    'HIPERTENSION_FAMILIAR', \n",
    "    'OTROS_ANTECEDENTES_VASCULARES', \n",
    "    'RIESGOS', \n",
    "    'ESTADO_CIVI', \n",
    "    'estrato', \n",
    "    'parentesco', \n",
    "    'PROGRAMA', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_columns = [\n",
    "    'AGRUPACION_DIASTOLICA',\n",
    "    'AGRUPACION_SISTOLICA',\n",
    "    'HIPERTENSION',\n",
    "    'HIPERTENSION_FAMILIAR',\n",
    "    'RIESGOS',\n",
    "    'estrato'\n",
    "]\n",
    "\n",
    "nominal_columns = [\n",
    "    'CANCER_MAMA_FAMILIAR',\n",
    "    'CANCER_OTRO_SITIO',\n",
    "    'CORONARIOS',\n",
    "    'CANCER_OTRO_SITIO_FAMILIAR',\n",
    "    'CORONARIOS_FAMILIAR',\n",
    "    'CEREBRAL',\n",
    "    'CEREBRAL_FAMILIAR',\n",
    "    'DIABETES',\n",
    "    'DIABETES_FAMILIAR',\n",
    "    'ENFERMEDAD_RENAL',\n",
    "    'ENFERMEDAD_RENAL_FAMILIAR',\n",
    "    'OTROS_ANTECEDENTES_VASCULARES',\n",
    "    'ESTADO_CIVI',\n",
    "    'parentesco',\n",
    "    'PROGRAMA'                  \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = df_train.copy()\n",
    "for column in ordinal_columns + nominal_columns + ['IMC']:\n",
    "    df_encoded[column] = df_encoded[column].astype('category')\n",
    "X = df_encoded.drop(columns=['Target'])\n",
    "y = df_encoded['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', enable_categorical=True)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='teal')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance using XGBoost')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.sample(frac=0.1, random_state=42)\n",
    "y_train_small = y_train.loc[X_train_small.index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['Cant_Fliar_riesgos', 'Cant_Fliar_CP', 'min_Tiempo_CP_Fliar', 'psa_min_gr_flia', 'psa_max_gr_flia', 'CANCER_MAMA_FAMILIAR', 'Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate dropping features\n",
    "- In order to be sure whether we decide to drop or not the already identified features, we will run a preliminary model to test with and without the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', enable_categorical=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "# Model 1: With all features\n",
    "X_all_features = df_encoded.drop(columns=['Target'])\n",
    "y = df_encoded['Target']\n",
    "\n",
    "f1_all_features = train_and_evaluate(X_all_features, y)\n",
    "print(f\"F1 Score with all features: {f1_all_features}\")\n",
    "\n",
    "# Model 2: Dropping variables with zero importance\n",
    "X_reduced_features = df_encoded.drop(columns=['Target'] + features_to_drop)\n",
    "\n",
    "f1_reduced_features = train_and_evaluate(X_reduced_features, y)\n",
    "print(f\"F1 Score after dropping zero-importance features: {f1_reduced_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping additional features, including `'Cant_Fliar_riesgos'`, `'Cant_Fliar_CP'`, `'min_Tiempo_CP_Fliar'`, `'psa_min_gr_flia'`, `'psa_max_gr_flia'`, and `'CANCER_MAMA_FAMILIAR'`, the model's performance improved. The F1 score increased from **0.5207** (with all features) to **0.5384** (after removing these features), indicating that simplifying the model by excluding both zero-importance features and those with minimal predictive power can enhance the modelâ€™s performance. By reducing noise from less significant features, the model was able to generalize better and make more accurate predictions, showcasing the benefits of feature selection in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline_________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_numeric_columns = [col for col in numeric_columns if col not in features_to_drop]\n",
    "updated_ordinal_columns = [col for col in ordinal_columns if col not in features_to_drop]\n",
    "updated_nominal_columns = [col for col in nominal_columns if col not in features_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('winsorizer', Winsorizer(capping_method='quantiles', tail='right', fold=0.05)),\n",
    "])\n",
    "\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal_encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "nominal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, updated_numeric_columns),\n",
    "        ('ord', ordinal_transformer, updated_ordinal_columns),\n",
    "        ('nom', nominal_transformer, updated_nominal_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('drop_columns', 'passthrough'),\n",
    "    ('preprocessor', preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying preprocessor pipeline\n",
    "- Imputation and dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=features_to_drop)\n",
    "y = df_train['Target']\n",
    "\n",
    "pipeline.fit(X)\n",
    "X_train_transformed = pipeline.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the pipeline output into a readable data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_columns = (\n",
    "    updated_numeric_columns + \n",
    "    updated_ordinal_columns + \n",
    "    list(pipeline.named_steps['preprocessor'].transformers_[2][1]['onehot'].get_feature_names_out(updated_nominal_columns))\n",
    ")\n",
    "\n",
    "X_train_transformed_df = pd.DataFrame(X_train_transformed, columns=transformed_columns)\n",
    "X_train_transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Revisar el conteo de valores atipicos !!!!!!!!!!!!!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iqr(df, numeric_columns):\n",
    "    \"\"\"\n",
    "    This function takes a dataframe and returns a dataframe that contains \n",
    "    the Interquartile Range (IQR) for each numeric column in the dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input dataframe\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Dataframe containing IQR values for each numeric column\n",
    "    \"\"\"\n",
    "    # Select numeric columns from the dataframe\n",
    "    df_numeric_columns = df[numeric_columns]\n",
    "    \n",
    "    # Calculate Q1 (25th percentile) and Q3 (75th percentile) for each numeric column\n",
    "    Q1 = df_numeric_columns.quantile(0.25)\n",
    "    Q3 = df_numeric_columns.quantile(0.75)\n",
    "    \n",
    "    # Calculate the Interquartile Range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Create a dataframe to store the IQR values\n",
    "    iqr_df = pd.DataFrame({\n",
    "        'Column': IQR.index,\n",
    "        'IQR': IQR.values\n",
    "    }).sort_values(by='IQR', ascending=False)\n",
    "    \n",
    "    return iqr_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr_result = calculate_iqr(df_train, numeric_columns)\n",
    "iqr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr_result_after = calculate_iqr(X_train_transformed_df, updated_numeric_columns)\n",
    "print(iqr_result_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA ....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt import UtilityFunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_small\n",
    "y_train = y_train_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated preprocessing pipeline\n",
    "# Make sure you have the correct categorization of columns: numeric, ordinal, and nominal\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('winsorizer', Winsorizer(capping_method='quantiles', tail='right', fold=0.05)),\n",
    "])\n",
    "\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal_encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "nominal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  # Added dense output for compatibility\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, updated_numeric_columns),  # Process numeric columns\n",
    "        ('ord', ordinal_transformer, updated_ordinal_columns),  # Process ordinal columns\n",
    "        ('nom', nominal_transformer, updated_nominal_columns)   # Process nominal columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Ensure that the preprocessing pipeline is used before PCA in your pipeline\n",
    "# Number of components for PCA (adjust as needed)\n",
    "n_components_pca = 5  # Adjust based on your dataset\n",
    "\n",
    "# Define the SVM evaluation function with the updated pipeline\n",
    "def svm_evaluate(C, gamma, kernel_choice):\n",
    "    kernel = 'linear' if kernel_choice < 0.5 else 'rbf'\n",
    "    \n",
    "    # Create a complete pipeline: PCA + preprocessing + SVM\n",
    "    model_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),  # Include the preprocessing pipeline\n",
    "        ('pca', PCA(n_components=n_components_pca, random_state=42)),  # Add PCA after preprocessing\n",
    "        ('svm', SVC(C=C, gamma=gamma, kernel=kernel, probability=True))  # SVM with hyperparameters\n",
    "    ])\n",
    "    \n",
    "    # Perform K-fold cross-validation and return mean ROC AUC score\n",
    "    roc_auc_scores = cross_val_score(model_pipeline, X_train, y_train, cv=3, scoring='roc_auc', verbose=0)\n",
    "    \n",
    "    return roc_auc_scores.mean()\n",
    "\n",
    "# Define the parameter bounds for Bayesian Optimization\n",
    "pbounds = {\n",
    "    'C': (1, 5),       # Regularization parameter\n",
    "    'gamma': (0.0001, 1),  # Kernel coefficient for 'rbf'\n",
    "    'kernel_choice': (0, 1)  # 0 for 'linear', 1 for 'rbf'\n",
    "}\n",
    "\n",
    "# Set up the Bayesian optimizer\n",
    "optimizer = BayesianOptimization(\n",
    "    f=svm_evaluate,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Run the optimization without the progress bar\n",
    "optimizer.maximize(init_points=2, n_iter=3)\n",
    "\n",
    "# Output the best parameters\n",
    "best_params = optimizer.max\n",
    "print(\"Best parameters found:\", best_params)\n",
    "\n",
    "# Train the final SVM model with the best parameters\n",
    "C_opt = best_params['params']['C']\n",
    "gamma_opt = best_params['params']['gamma']\n",
    "kernel_opt = 'linear' if best_params['params']['kernel_choice'] < 0.5 else 'rbf'\n",
    "\n",
    "# Final pipeline with best hyperparameters\n",
    "best_svm_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),  # Include the preprocessing pipeline\n",
    "    ('pca', PCA(n_components=n_components_pca, random_state=42)),  # Add PCA\n",
    "    ('svm', SVC(C=C_opt, gamma=gamma_opt, kernel=kernel_opt, probability=True))  # Best SVM model\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the final model\n",
    "best_svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model on the test set using ROC AUC\n",
    "y_pred_proba = best_svm_model.predict_proba(X_test)[:, 1]  # Probability estimates for the positive class\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"Final ROC AUC Score on the test set: {test_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usar diferentes kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Train the final SVM model with the best parameters\n",
    "# C_opt = best_params['params']['C']\n",
    "# gamma_opt = best_params['params']['gamma']\n",
    "# kernel_opt = 'linear' if best_params['params']['kernel_choice'] < 0.5 else 'rbf'\n",
    "\n",
    "# # Final pipeline with best hyperparameters\n",
    "# best_svm_model = Pipeline([\n",
    "#     ('preprocessor', preprocessor),  # Include the preprocessing pipeline\n",
    "#     ('svm', SVC(C=C_opt, gamma=gamma_opt, kernel=kernel_opt, probability=True))\n",
    "# ])\n",
    "\n",
    "# # Fit the final model\n",
    "# best_svm_model.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the final model on the test set using ROC AUC\n",
    "# y_pred_proba = best_svm_model.predict_proba(X_test)[:, 1]  # Probability estimates for the positive class\n",
    "# test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "# print(f\"Final ROC AUC Score on the test set: {test_roc_auc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
